struct POMDP
   Î³ # discount factor
   ğ’® # state space
   ğ’œ # action space
   ğ’ª # observation space
   T # transition function
   R # reward function
   O # observation function
   TRO # sample transition, reward, and observation
end

# Algorithm 19.2. A method that
# updates a discrete belief based on
# equation (19.7), where b is a vector and ğ’« is the POMDP model. If
# the given observation has a zero
# likelihood, a uniform distribution
# is returned.
function update(b::Vector{Float64}, ğ’«, a, o)
   ğ’®, T, O = ğ’«.ğ’®, ğ’«.T, ğ’«.O
   bâ€² = similar(b)
   for (iâ€², sâ€²) in enumerate(ğ’®)
      po = O(a, sâ€², o)
      bâ€²[iâ€²] = po * sum(T(s, a, sâ€²) * b[i] for (i, s) in enumerate(ğ’®))
   end
   if sum(bâ€²) â‰ˆ 0.0
      fill!(bâ€², 1)
   end
   return normalize!(bâ€², 1)
end

# Algorithm 19.3. The Kalman filter,
# which updates beliefs in the form
# of Gaussian distributions. The current belief is represented by Î¼b and
# Î£b, and ğ’« contains the matrices that
# define linear Gaussian dynamics
# and observation model. This ğ’« can
# be defined using a composite type
# or a named tuple.

struct KalmanFilter
   Î¼b # mean vector
   Î£b # covariance matrix
end

function update(b::KalmanFilter, ğ’«, a, o)
   Î¼b, Î£b = b.Î¼b, b.Î£b
   Ts, Ta, Os = ğ’«.Ts, ğ’«.Ta, ğ’«.Os
   Î£s, Î£o = ğ’«.Î£s, ğ’«.Î£o
   # predict
   Î¼p = Ts*Î¼b + Ta*a
   Î£p = Ts*Î£b*Ts' + Î£s
   # update
   K = Î£p*Os'/(Os*Î£p*Os' + Î£o)
   Î¼bâ€² = Î¼p + K*(o - Os*Î¼p)
   Î£bâ€² = (I - K*Os)*Î£p
   return KalmanFilter(Î¼bâ€², Î£bâ€²)
end

struct ExtendedKalmanFilter
   Î¼b # mean vector
   Î£b # covariance matrix
end

import ForwardDiff: jacobian
function update(b::ExtendedKalmanFilter, ğ’«, a, o)
   Î¼b, Î£b = b.Î¼b, b.Î£b
   fT, fO = ğ’«.fT, ğ’«.fO
   Î£s, Î£o = ğ’«.Î£s, ğ’«.Î£o
   # predict
   Î¼p = fT(Î¼b, a)
   Ts = jacobian(s->fT(s, a), Î¼b)
   Os = jacobian(fO, Î¼p)
   Î£p = Ts*Î£b*Ts' + Î£s
   # update
   K = Î£p*Os'/(Os*Î£p*Os' + Î£o)
   Î¼bâ€² = Î¼p + K*(o - fO(Î¼p))
   Î£bâ€² = (I - K*Os)*Î£p
   return ExtendedKalmanFilter(Î¼bâ€², Î£bâ€²)
end

# Algorithm 19.5. The unscented
# Kalman filter, an extension of the
# Kalman filter to problems with
# nonlinear Gaussian dynamics. The
# current belief is represented by
# mean Î¼b and covariance Î£b. The
# problem ğ’« specifies the nonlinear
# dynamics using the mean transition dynamics function fT and
# mean observation dynamics function fO. The sigma points used in
# the unscented transforms are controlled by the scalars Î±, Î², and Îº.

struct UnscentedKalmanFilter
   Î¼b # mean vector
   Î£b # covariance matrix
   Î» # spread parameter
end

function unscented_transform(Î¼, Î£, f, Î», ws)
   n = length(Î¼)
   Î” = sqrt((n + Î») * Î£)
   S = [Î¼]
   for i in 1:n
      push!(S, Î¼ + Î”[:,i])
      push!(S, Î¼ - Î”[:,i])
   end
   Sâ€² = f.(S)
   Î¼â€² = sum(w*s for (w,s) in zip(ws, Sâ€²))
   Î£â€² = sum(w*(s - Î¼â€²)*(s - Î¼â€²)' for (w,s) in zip(ws, Sâ€²))
   return (Î¼â€², Î£â€², S, Sâ€²)
end

function update(b::UnscentedKalmanFilter, ğ’«, a, o)
   Î¼b, Î£b, Î» = b.Î¼b, b.Î£b, b.Î»
   fT, fO = ğ’«.fT, ğ’«.fO
   n = length(Î¼b)
   ws = [Î» / (n + Î»); fill(1/(2(n + Î»)), 2n)]
   # predict
   Î¼p, Î£p, Sp, Spâ€² = unscented_transform(Î¼b, Î£b, s->fT(s,a), Î», ws)
   Î£p += ğ’«.Î£s
   # update
   Î¼o, Î£o, So, Soâ€² = unscented_transform(Î¼p, Î£p, fO, Î», ws)
   Î£o += ğ’«.Î£o
   Î£po = sum(w*(s - Î¼p)*(sâ€² - Î¼o)' for (w,s,sâ€²) in zip(ws, So, Soâ€²))
   K = Î£po / Î£o
   Î¼bâ€² = Î¼p + K*(o - Î¼o)
   Î£bâ€² = Î£p - K*Î£o*K'
   return UnscentedKalmanFilter(Î¼bâ€², Î£bâ€², Î»)
end

struct ParticleFilter
   states # vector of state samples
end

function update(b::ParticleFilter, ğ’«, a, o)
   T, O = ğ’«.T, ğ’«.O
   states = [rand(T(s, a)) for s in b.states]
   weights = [O(a, sâ€², o) for sâ€² in states]
   D = SetCategorical(states, weights)
   return ParticleFilter(rand(D, length(states)))
end

struct RejectionParticleFilter
   states # vector of state samples
end

function update(b::RejectionParticleFilter, ğ’«, a, o)
   T, O = ğ’«.T, ğ’«.O
   states = similar(b.states)
   i = 1
   while i â‰¤ length(states)
      s = rand(b.states)
      sâ€² = rand(T(s,a))
      if rand(O(a,sâ€²)) == o
         states[i] = sâ€²
         i += 1
      end
   end
   return RejectionParticleFilter(states)
end

struct InjectionParticleFilter
   states # vector of state samples
   m_inject # number of samples to inject
   D_inject # injection distribution
end

function update(b::InjectionParticleFilter, ğ’«, a, o)
   T, O, m_inject, D_inject = ğ’«.T, ğ’«.O, b.m_inject, b.D_inject
   states = [rand(T(s, a)) for s in b.states]
   weights = [O(a, sâ€², o) for sâ€² in states]
   D = SetCategorical(states, weights)
   m = length(states)
   states = vcat(rand(D, m - m_inject), rand(D_inject, m_inject))
   return InjectionParticleFilter(states, m_inject, D_inject)
end

mutable struct AdaptiveInjectionParticleFilter
   states # vector of state samples
   w_slow # slow moving average
   w_fast # fast moving average
   Î±_slow # slow moving average parameter
   Î±_fast # fast moving average parameter
   Î½ # injection parameter
   D_inject # injection distribution
end

function update(b::AdaptiveInjectionParticleFilter, ğ’«, a, o)
   T, O = ğ’«.T, ğ’«.O
   w_slow, w_fast, Î±_slow, Î±_fast, Î½, D_inject =
   b.w_slow, b.w_fast, b.Î±_slow, b.Î±_fast, b.Î½, b.D_inject
   states = [rand(T(s, a)) for s in b.states]
   weights = [O(a, sâ€², o) for sâ€² in states]
   w_mean = mean(weights)
   w_slow += Î±_slow*(w_mean - w_slow)
   w_fast += Î±_fast*(w_mean - w_fast)
   m = length(states)
   m_inject = round(Int, m * max(0, 1.0 - Î½*w_fast / w_slow))
   D = SetCategorical(states, weights)
   states = vcat(rand(D, m - m_inject), rand(D_inject, m_inject))
   b.w_slow, b.w_fast = w_slow, w_fast
   return AdaptiveInjectionParticleFilter(states, w_slow, w_fast, Î±_slow, Î±_fast, Î½, D_inject)
end